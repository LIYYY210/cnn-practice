{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "after 0 train step,validate accuracyusing average model is 0.084\n",
      "after 1000 train step,validate accuracyusing average model is 0.9764\n",
      "after 2000 train step,validate accuracyusing average model is 0.9806\n",
      "after 3000 train step,validate accuracyusing average model is 0.981\n",
      "after 4000 train step,validate accuracyusing average model is 0.9824\n",
      "after 5000 train step,validate accuracyusing average model is 0.9832\n",
      "after 6000 train step,validate accuracyusing average model is 0.9836\n",
      "after 7000 train step,validate accuracyusing average model is 0.9836\n",
      "after 8000 train step,validate accuracyusing average model is 0.9846\n",
      "after 9000 train step,validate accuracyusing average model is 0.9846\n",
      "after 10000 train step,test accuracy using averagemodel is 0.9843\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77518\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "input_node = 784\n",
    "output_node = 10\n",
    "layer1_node = 500\n",
    "batch_size = 50\n",
    "learning_rate_base = 0.8\n",
    "learning_rate_decay = 0.99\n",
    "regularization_rate = 0.0001\n",
    "training_step = 10000\n",
    "moving_average_decay = 0.99\n",
    "\n",
    "def inference(input_tensor,avg_class,w1,b1,w2,b2):\n",
    "    if avg_class == None:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,w1)+b1)\n",
    "        return tf.matmul(layer1,w2)+b2\n",
    "    else:\n",
    "        layer1 = tf.nn.relu(tf.matmul(input_tensor,avg_class.average(w1))+avg_class.average(b1))\n",
    "        return tf.matmul(layer1,avg_class.average(w2))+avg_class.average(b2)\n",
    "\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32,[None,input_node],name='x-input')\n",
    "    y_ =tf.placeholder(tf.float32,[None,output_node],name='y-output')\n",
    "    w1 = tf.Variable(tf.truncated_normal([input_node,layer1_node],stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1,shape=[layer1_node]))\n",
    "    w2 = tf.Variable(tf.truncated_normal([layer1_node,output_node],stddev=0.1))\n",
    "    b2 = tf.Variable(tf.constant(0.1,shape=[output_node]))\n",
    "    y = inference(x,None,w1,b1,w2,b2)\n",
    "    global_step = tf.Variable(0,trainable=False)\n",
    "    variable_averages=tf.train.ExponentialMovingAverage(moving_average_decay,global_step)\n",
    "    variable_averages_op=variable_averages.apply(tf.trainable_variables())\n",
    "    average_y = inference(x,variable_averages,w1,b1,w2,b2)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_,1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "    regularization = regularizer(w1)+regularizer(w2)\n",
    "    loss = cross_entropy_mean+regularization\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate_base,global_step,mnist.train.num_examples/batch_size,learning_rate_decay)\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "    with tf.control_dependencies([train_step,variable_averages_op]):\n",
    "        train_op=tf.no_op(name='train')\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        validate_feed = {x:mnist.validation.images,y_:mnist.validation.labels}\n",
    "        test_feed = {x:mnist.test.images,y_:mnist.test.labels}\n",
    "        for i in range(training_step):\n",
    "            if i%1000==0:\n",
    "                validate_acc=sess.run(accuracy,feed_dict=validate_feed)\n",
    "                print(\"after %d train step,validate accuracy\" \"using average model is %g\" % (i,validate_acc))\n",
    "            xs,ys=mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_op,feed_dict={x:xs,y_:ys})\n",
    "        test_acc = sess.run(accuracy,feed_dict=test_feed)\n",
    "        print(\"after %d train step,test accuracy using average\" \"model is %g\" % (training_step,test_acc))\n",
    "\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    train(mnist)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
